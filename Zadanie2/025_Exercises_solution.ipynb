{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9TPV0od57UI2"
      },
      "source": [
        "# Exercises\n",
        "\n",
        "There are three exercises in this notebook:\n",
        "\n",
        "1. Use the cross-validation method to test the linear regression with different $\\alpha$ values, at least three.\n",
        "2. Implement a SGD method that will train the Lasso regression for 10 epochs.\n",
        "3. Extend the Fisher's classifier to work with two features. Use the class as the $y$."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TUYZn2417UI5"
      },
      "source": [
        "## 1. Cross-validation linear regression\n",
        "\n",
        "You need to change the variable ``alpha`` to be a list of alphas. Next do a loop and finally compare the results."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Je6IxIYZ7UI5",
        "outputId": "ecabe588-5000-49f0-ac2e-6c282b16a67c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "-1.0   [[26.66709687  0.4429618 ]]\n",
            "-0.75   [[37.39167938  0.38224917]]\n",
            "-0.5   [[62.54823018  0.23983657]]\n",
            "-0.25   [[191.1815848   -0.48836253]]\n",
            "-0.1   [[-817.017374      5.21909359]]\n",
            "0.1   [[-101.72397081    1.16978757]]\n",
            "0.25   [[-61.4032918    0.94153034]]\n",
            "0.5   [[-36.97522016   0.80324169]]\n",
            "0.75   [[-26.45132728   0.74366517]]\n",
            "1.0   [[-20.59044706   0.71048616]]\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "x = np.array([188, 181, 197, 168, 167, 187, 178, 194, 140, 176, 168, 192, 173, 142, 176]).reshape(-1, 1).reshape(15,1)\n",
        "y = np.array([141, 106, 149, 59, 79, 136, 65, 136, 52, 87, 115, 140, 82, 69, 121]).reshape(-1, 1).reshape(15,1)\n",
        "\n",
        "x = np.asmatrix(np.c_[np.ones((15,1)),x])\n",
        "\n",
        "I = np.identity(2)\n",
        "alpha = [-1.0, -0.75, -0.5, -0.25, -0.1, 0.1, 0.25, 0.5, 0.75, 1.0]\n",
        "\n",
        "#iterating through alphas\n",
        "result=[]\n",
        "for j in alpha:\n",
        "    w = np.linalg.inv(x.T*x + j * I)*x.T*y\n",
        "    w=w.ravel()\n",
        "    result.append(w)\n",
        "\n",
        "#comapring results\n",
        "i=0\n",
        "while i<len(alpha):\n",
        "    print(alpha[i], \" \", result[i])\n",
        "    i=i+1\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nuUOxnlf7UI8"
      },
      "source": [
        "## 2. Implement based on the Ridge regression example, the Lasso regression.\n",
        "\n",
        "Please implement the SGD method and compare the results with the sklearn Lasso regression results."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def sgd(x, y, lr, n):\n",
        "    w = 1 #np.random.rand(1,10) - doesn't really change match, adds dimensions x below is (15,1) so I left 1 here\n",
        "    b = 1\n",
        "    i=1\n",
        "\n",
        "    while i < n:\n",
        "        error = y - (x * w + b)\n",
        "\n",
        "        w = w - lr * (sum(x * error) * -2 / (np.linalg.norm(x) ** 2))\n",
        "        b = b - lr * (sum(error) * (-(2 / y.size)))\n",
        "        i=i+1\n",
        "\n",
        "    return b[0], w[0]"
      ],
      "metadata": {
        "id": "WXJNbtM7fQ-6"
      },
      "execution_count": 126,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 127,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OwpskYGo7UI9",
        "outputId": "493760e1-bb5d-4cb7-9235-a831b8435c68"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "10 epoch  (-36.34501185508552, 0.8003962894878118)\n",
            "Lasso  [-180.8579086] [1.61776499]\n",
            "Epoch equal to lasso  (-180.8968424354465, 1.6179879655822196)\n"
          ]
        }
      ],
      "source": [
        "import sklearn\n",
        "\n",
        "x = np.array([188, 181, 197, 168, 167, 187, 178, 194, 140, 176, 168, 192, 173, 142, 176]).reshape(-1, 1).reshape(15,1)\n",
        "y = np.array([141, 106, 149, 59, 79, 136, 65, 136, 52, 87, 115, 140, 82, 69, 121]).reshape(-1, 1).reshape(15,1)\n",
        "\n",
        "#x = np.asmatrix(np.c_[np.ones((15,1)),x]) -\n",
        "\n",
        "I = np.identity(2)\n",
        "alpha = 0.1\n",
        "\n",
        "\n",
        "print(\"10 epoch \", sgd(x=x, y=y, lr=0.1, n=10)) #Top part mentions 10 epochs\n",
        "\n",
        "lr = Lasso(alpha = 0.1, max_iter = 10)\n",
        "lr.fit(X=x, y=y)\n",
        "print(\"Lasso \", lr.intercept_, lr.coef_) #Lower part comapring lasso with SGD, and I can't really change number of epochs in lasso\n",
        "\n",
        "print(\"Epoch equal to lasso \", sgd(x=x, y=y, lr=0.1, n=10000)) #So there is a second use of sgd with 10000 epochs\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Di6YP7Rg7UI9"
      },
      "source": [
        "## 3. Extend the Fisher's classifier\n",
        "\n",
        "Please extend the targets of the ``iris_data`` variable and use it as the $y$."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nw4kDjEf7UI9",
        "outputId": "8d25e178-b2bf-43e4-ee32-6d64c869e738"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0.92478522 1.05141831]\n",
            " [0.88521238 1.03558917]\n",
            " [0.90104152 1.01976004]\n",
            " [0.89312695 1.01184547]\n",
            " [0.93269979 1.04350374]\n",
            " [0.95644349 1.07516201]\n",
            " [0.91687065 1.01184547]\n",
            " [0.91687065 1.04350374]\n",
            " [0.87729781 0.99601633]\n",
            " [0.89312695 1.03558917]\n",
            " [0.94061436 1.07516201]\n",
            " [0.91687065 1.02767461]\n",
            " [0.88521238 1.02767461]\n",
            " [0.88521238 0.98810177]\n",
            " [0.96435806 1.10682029]\n",
            " [0.99601633 1.09890572]\n",
            " [0.95644349 1.07516201]\n",
            " [0.92478522 1.05141831]\n",
            " [0.94852893 1.09890572]\n",
            " [0.94852893 1.05141831]\n",
            " [0.91687065 1.07516201]\n",
            " [0.94061436 1.05141831]\n",
            " [0.93269979 1.01184547]\n",
            " [0.90895609 1.05141831]\n",
            " [0.91687065 1.02767461]\n",
            " [0.88521238 1.04350374]\n",
            " [0.91687065 1.04350374]\n",
            " [0.92478522 1.05933288]\n",
            " [0.91687065 1.05933288]\n",
            " [0.90104152 1.01976004]\n",
            " [0.89312695 1.02767461]\n",
            " [0.91687065 1.07516201]\n",
            " [0.97227263 1.05933288]\n",
            " [0.9801872  1.08307658]\n",
            " [0.89312695 1.03558917]\n",
            " [0.90104152 1.04350374]\n",
            " [0.92478522 1.08307658]\n",
            " [0.93269979 1.03558917]\n",
            " [0.88521238 0.99601633]\n",
            " [0.91687065 1.05141831]\n",
            " [0.92478522 1.04350374]\n",
            " [0.82981041 1.0039309 ]\n",
            " [0.90104152 0.99601633]\n",
            " [0.92478522 1.04350374]\n",
            " [0.94852893 1.05141831]\n",
            " [0.88521238 1.02767461]\n",
            " [0.94852893 1.05141831]\n",
            " [0.90104152 1.01184547]\n",
            " [0.94061436 1.06724745]\n",
            " [0.90895609 1.04350374]\n",
            " [0.90104152 1.2017951 ]\n",
            " [0.90104152 1.15430769]\n",
            " [0.89312695 1.19388053]\n",
            " [0.82981041 1.08307658]\n",
            " [0.86938325 1.16222226]\n",
            " [0.86938325 1.09890572]\n",
            " [0.90895609 1.14639313]\n",
            " [0.83772498 1.03558917]\n",
            " [0.87729781 1.17013683]\n",
            " [0.86146868 1.05933288]\n",
            " [0.8060667  1.04350374]\n",
            " [0.88521238 1.11473485]\n",
            " [0.82189584 1.12264942]\n",
            " [0.87729781 1.13056399]\n",
            " [0.87729781 1.09099115]\n",
            " [0.89312695 1.1780514 ]\n",
            " [0.88521238 1.09099115]\n",
            " [0.86146868 1.10682029]\n",
            " [0.82189584 1.13847856]\n",
            " [0.84563954 1.09099115]\n",
            " [0.90104152 1.11473485]\n",
            " [0.86938325 1.13056399]\n",
            " [0.84563954 1.14639313]\n",
            " [0.86938325 1.13056399]\n",
            " [0.87729781 1.15430769]\n",
            " [0.88521238 1.17013683]\n",
            " [0.86938325 1.18596596]\n",
            " [0.88521238 1.1780514 ]\n",
            " [0.87729781 1.12264942]\n",
            " [0.85355411 1.09890572]\n",
            " [0.83772498 1.08307658]\n",
            " [0.83772498 1.08307658]\n",
            " [0.86146868 1.10682029]\n",
            " [0.86146868 1.12264942]\n",
            " [0.88521238 1.07516201]\n",
            " [0.91687065 1.12264942]\n",
            " [0.89312695 1.1780514 ]\n",
            " [0.82981041 1.14639313]\n",
            " [0.88521238 1.09099115]\n",
            " [0.84563954 1.08307658]\n",
            " [0.85355411 1.08307658]\n",
            " [0.88521238 1.13056399]\n",
            " [0.85355411 1.10682029]\n",
            " [0.82981041 1.04350374]\n",
            " [0.86146868 1.09099115]\n",
            " [0.88521238 1.09890572]\n",
            " [0.87729781 1.09890572]\n",
            " [0.87729781 1.13847856]\n",
            " [0.84563954 1.05141831]\n",
            " [0.86938325 1.09890572]\n",
            " [0.90895609 1.14639313]\n",
            " [0.86146868 1.10682029]\n",
            " [0.88521238 1.20970967]\n",
            " [0.87729781 1.14639313]\n",
            " [0.88521238 1.16222226]\n",
            " [0.88521238 1.24928251]\n",
            " [0.84563954 1.03558917]\n",
            " [0.87729781 1.2255388 ]\n",
            " [0.84563954 1.1780514 ]\n",
            " [0.93269979 1.21762424]\n",
            " [0.90104152 1.16222226]\n",
            " [0.86146868 1.15430769]\n",
            " [0.88521238 1.18596596]\n",
            " [0.84563954 1.09890572]\n",
            " [0.86938325 1.10682029]\n",
            " [0.90104152 1.15430769]\n",
            " [0.88521238 1.16222226]\n",
            " [0.94852893 1.25719708]\n",
            " [0.85355411 1.25719708]\n",
            " [0.82189584 1.12264942]\n",
            " [0.90104152 1.19388053]\n",
            " [0.86938325 1.09099115]\n",
            " [0.86938325 1.25719708]\n",
            " [0.86146868 1.14639313]\n",
            " [0.90895609 1.1780514 ]\n",
            " [0.90104152 1.21762424]\n",
            " [0.86938325 1.13847856]\n",
            " [0.88521238 1.13056399]\n",
            " [0.86938325 1.15430769]\n",
            " [0.88521238 1.21762424]\n",
            " [0.86938325 1.23345337]\n",
            " [0.94852893 1.27302621]\n",
            " [0.86938325 1.15430769]\n",
            " [0.86938325 1.14639313]\n",
            " [0.85355411 1.13056399]\n",
            " [0.88521238 1.25719708]\n",
            " [0.91687065 1.14639313]\n",
            " [0.89312695 1.15430769]\n",
            " [0.88521238 1.12264942]\n",
            " [0.89312695 1.19388053]\n",
            " [0.89312695 1.1780514 ]\n",
            " [0.89312695 1.19388053]\n",
            " [0.86146868 1.10682029]\n",
            " [0.90104152 1.18596596]\n",
            " [0.90895609 1.1780514 ]\n",
            " [0.88521238 1.1780514 ]\n",
            " [0.84563954 1.14639313]\n",
            " [0.88521238 1.16222226]\n",
            " [0.91687065 1.13847856]\n",
            " [0.88521238 1.11473485]]\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.datasets import load_iris\n",
        "\n",
        "iris_data = load_iris()\n",
        "iris_df = pd.DataFrame(iris_data.data,columns=iris_data.feature_names)\n",
        "\n",
        "x = iris_df[['sepal width (cm)', 'sepal length (cm)']].values #added sepal lenght from below\n",
        "y = iris_data.target.reshape(-1, 1)\n",
        "\n",
        "dataset_size = np.size(x)\n",
        "\n",
        "mean_x, mean_y = np.mean(x), np.mean(y)\n",
        "\n",
        "SS_xy = np.sum(y * x) - dataset_size * mean_y * mean_x\n",
        "SS_xx = np.sum(x * x) - dataset_size * mean_x * mean_x\n",
        "\n",
        "a = SS_xy / SS_xx\n",
        "b = mean_y - a * mean_x\n",
        "\n",
        "\n",
        "y_pred = a * x + b\n",
        "print(y_pred)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.5.3"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}